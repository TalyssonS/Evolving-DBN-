{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddcb530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:37.081248Z",
     "start_time": "2022-09-13T04:00:32.889378Z"
    }
   },
   "outputs": [],
   "source": [
    "import DefModules as DM\n",
    "from datetime import datetime, timedelta\n",
    "FullOpt =  True\n",
    "from pgmpy.inference import VariableElimination\n",
    "import jupyter_contrib_nbextensions\n",
    "import random\n",
    "import warnings\n",
    "import sys \n",
    "import logging\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import psycopg2 as pg\n",
    "import sqlalchemy as sq\n",
    "import networkx as nx\n",
    "logging.disable()\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import HillClimbSearch\n",
    "FullOpt =  True #True é para usar HC e false busca exaustiva\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "from pgmpy.estimators import BdeuScore\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b788a428",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:37.092186Z",
     "start_time": "2022-09-13T04:00:37.081248Z"
    }
   },
   "outputs": [],
   "source": [
    "def smooth(y, box_pts):\n",
    "    vi = y[0]\n",
    "    vf = y[len(y)-1]\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    y_smooth[0] = vi\n",
    "    y_smooth[len(y_smooth)-1] = vf\n",
    "    return y_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d9a041",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:37.202890Z",
     "start_time": "2022-09-13T04:00:37.096174Z"
    }
   },
   "outputs": [],
   "source": [
    "def errorf (real,forecast):\n",
    "    error=[]\n",
    "    for i in range(len(real)):\n",
    "        error.append(real[i]-forecast[i])\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfb8cf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:37.288661Z",
     "start_time": "2022-09-13T04:00:37.206879Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_connection():\n",
    "    '''\n",
    "    FUNCTION TO CONNECT TO THE POSTGRESQL DATABASE\n",
    "    '''\n",
    "    conn = pg.connect(dbname='postgres', user = 'postgres', password = 123, host = 'localhost')\n",
    "    return conn\n",
    "def get_connection():\n",
    "    '''\n",
    "    FUNCTION TO CONNECT TO THE POSTGRESQL DATABASE AND RETURN THE SQLACHEMY ENGINE OBJECT\n",
    "    -----------\n",
    "    output: object\n",
    "        SQLACHEMY ENGINE OBJECT - POSTGRESQL DATABASE CONNECTION\n",
    "    '''\n",
    "    user = 'postgres'\n",
    "    password = 123\n",
    "    host = 'localhost'\n",
    "    port = 5432\n",
    "    database = 'postgres'\n",
    "    return sq.create_engine(url=\"postgresql://{0}:{1}@{2}:{3}/{4}\".format(user, password, host, port, database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4bdb801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:37.373435Z",
     "start_time": "2022-09-13T04:00:37.291652Z"
    }
   },
   "outputs": [],
   "source": [
    "def blanket(model,variable):\n",
    "    '''\n",
    "    Function to extract the Markov Blanket of the target variable (reduces the structure)\n",
    "    -----------\n",
    "    input:\n",
    "    model: list\n",
    "        list of edges\n",
    "        \n",
    "    variable: str\n",
    "        name of the target variable\n",
    "        \n",
    "    output:\n",
    "    blanket: list\n",
    "        list of edges \n",
    "    '''\n",
    "    blanket=[]\n",
    "    sons=[]\n",
    "    for i in model:\n",
    "        if i[0]==variable or i[1]==variable:\n",
    "            blanket.append(i)\n",
    "        if i[0]==variable:\n",
    "            sons.append(i[1])\n",
    "    for i in model:\n",
    "        if i[1] in sons and i[0]!=variable:\n",
    "            blanket.append(i)\n",
    "    return blanket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a8ca24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:37.459204Z",
     "start_time": "2022-09-13T04:00:37.376425Z"
    }
   },
   "outputs": [],
   "source": [
    "def verifica_remove_ciclos(edges):\n",
    "    '''\n",
    "    Function to verify if the edges is a DAG and to try remove cycles\n",
    "    -----------\n",
    "    input:\n",
    "    edges: list\n",
    "        list of edges\n",
    "                \n",
    "    output:\n",
    "    blanket: list\n",
    "        list of edges \n",
    "    '''\n",
    "    edgesdag = edges #recebe o próprio modelo\n",
    "    #Verifica se tem ciclos e tenta remover invertendo uma aresta\n",
    "    if ~nx.is_directed_acyclic_graph(nx.DiGraph(edgesdag[:])):\n",
    "        for i in edgesdag:  # (3) flip single edge\n",
    "            edges2 = edgesdag.copy()\n",
    "            edges2.extend([i[::-1]])\n",
    "            new_edges = edges2.copy()\n",
    "            new_edges.remove(i)\n",
    "            if nx.is_directed_acyclic_graph(nx.DiGraph(new_edges[:])):\n",
    "                edgesdag = new_edges.copy()\n",
    "                break\n",
    "    #Verifica se tem ciclos e tenta remover invertendo duas arestas\n",
    "    if ~nx.is_directed_acyclic_graph(nx.DiGraph(edgesdag[:])):\n",
    "        for i in edgesdag:\n",
    "            for j in edgesdag:# (3) flip two edges\n",
    "                if i != j:\n",
    "                    edges2 = edgesdag.copy()\n",
    "                    edges2.extend([i[::-1]])\n",
    "                    edges2.extend([j[::-1]])\n",
    "                    new_edges = edges2.copy()\n",
    "                    new_edges.remove(i)\n",
    "                    new_edges.remove(j)\n",
    "                    if nx.is_directed_acyclic_graph(nx.DiGraph(new_edges[:])):\n",
    "                        edgesdag = new_edges.copy()\n",
    "                        breaker = True\n",
    "                        break\n",
    "            if breaker:\n",
    "                break\n",
    "    #Verifica se tem ciclos e tenta remover invertendo uma aresta e excluindo uma aresta\n",
    "    if ~nx.is_directed_acyclic_graph(nx.DiGraph(edgesdag[:])):\n",
    "        for i in edgesdag:\n",
    "            for j in edgesdag:# (3) flip two edges\n",
    "                if i != j:\n",
    "                    edges2 = edgesdag.copy()\n",
    "                    edges2.extend([i[::-1]])\n",
    "                    new_edges = edges2.copy()\n",
    "                    new_edges.remove(i)\n",
    "                    new_edges.remove(j)\n",
    "                    if nx.is_directed_acyclic_graph(nx.DiGraph(new_edges[:])):\n",
    "                        edgesdag = new_edges.copy()\n",
    "                        breaker = True\n",
    "                        break\n",
    "            if breaker:\n",
    "                break\n",
    "    return edgesdag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a1e2199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:37.543223Z",
     "start_time": "2022-09-13T04:00:37.462195Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_dates(pais):\n",
    "    q = '''select distinct cast(\"Date\" as DATE) as datas from pre_processed_data.dbn_features_selected_{pais} order by datas'''.format(pais=pais)\n",
    "    conn = open_connection()\n",
    "    date = pd.read_sql(q,conn)\n",
    "    conn.close()\n",
    "    datas = date['datas'].tolist()\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d4c1a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:37.627992Z",
     "start_time": "2022-09-13T04:00:37.547209Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset(pais,date_ini, date_fin):\n",
    "    q = '''select * \n",
    "    from pre_processed_data.dbn_features_selected_{pais} where \"Date\" between '{date_ini}' and '{date_fin}' '''.format(pais=pais,date_ini=date_ini,date_fin=date_fin)\n",
    "    conn = open_connection()\n",
    "    dataset = pd.read_sql(q,conn)\n",
    "    conn.close()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "916e726f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:37.838431Z",
     "start_time": "2022-09-13T04:00:37.630985Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset_allfeatures(pais,date_ini, date_fin):\n",
    "    q = '''select * \n",
    "    from pre_processed_data.dbn_{pais} where \"Date\" between '{date_ini}' and '{date_fin}' '''.format(pais=pais,date_ini=date_ini,date_fin=date_fin)\n",
    "    conn = open_connection()\n",
    "    dataset = pd.read_sql(q,conn)\n",
    "    conn.close()\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b9c761a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:38.006980Z",
     "start_time": "2022-09-13T04:00:37.997008Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_edges_frequencies(best_model, edges_possibilities, edges_frequency):\n",
    "    if not edges_possibilities:\n",
    "        edges_possibilities = best_model\n",
    "        for p in range(len(edges_possibilities)):\n",
    "            edges_frequency.append(1)\n",
    "    else:\n",
    "        for v in range(len(best_model)):\n",
    "            if best_model[v] not in edges_possibilities:\n",
    "                edges_possibilities.append(best_model[v])\n",
    "                edges_frequency.append(1)\n",
    "            else:\n",
    "                for f in range(len(edges_possibilities)):\n",
    "                    if best_model[v] == edges_possibilities[f]:\n",
    "                        edges_frequency[f]=edges_frequency[f]+1\n",
    "    return edges_possibilities, edges_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73fb9e2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:38.431844Z",
     "start_time": "2022-09-13T04:00:38.406910Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_threshold_select_edges(k, edges_possibilities, edges_frequency):\n",
    "    fth = 1/3+np.sqrt(2/k)\n",
    "    if fth>0.4:\n",
    "        fth=0.4\n",
    "    edges_frequency_v=[edges_frequency[i]/k for i in range(len(edges_frequency))]\n",
    "    edges=[]\n",
    "    for i in range(len(edges_possibilities)):\n",
    "        if edges_frequency_v[i]>=fth and edges_possibilities[i] not in edges:\n",
    "            if edges_possibilities[i][::-1] not in edges_possibilities:\n",
    "                edges.append(edges_possibilities[i])\n",
    "            else: \n",
    "                if edges_frequency_v[i] > edges_frequency_v[edges_possibilities.index(edges_possibilities[i][::-1])]:\n",
    "                    edges.append(edges_possibilities[i])\n",
    "                else: \n",
    "                    edges.append(edges_possibilities[i][::-1])\n",
    "        elif edges_frequency_v[i]<fth:\n",
    "            for j in range(len(edges_possibilities)):\n",
    "                if edges_possibilities[i]==edges_possibilities[j][::-1]:\n",
    "                    if edges_frequency_v[i]+edges_frequency_v[j]>=fth:\n",
    "                        if edges_frequency_v[i]>edges_frequency_v[j]:\n",
    "                            edges.append(edges_possibilities[i])\n",
    "                        if edges_frequency_v[i]<edges_frequency_v[j]:\n",
    "                            edges.append(edges_possibilities[j])\n",
    "                        if edges_frequency_v[i]==edges_frequency_v[j]:\n",
    "                            auxci=0\n",
    "                            auxcj=0\n",
    "                            for s in range(len(edges)):\n",
    "                                if edges[s]==edges_possibilities[i]:\n",
    "                                    auxci=auxci+1\n",
    "                                if edges[s]==edges_possibilities[j]:\n",
    "                                    auxcj=auxcj+1\n",
    "                            if auxci>0:\n",
    "                                edges.append(edges_possibilities[i])\n",
    "                            elif auxcj>0:\n",
    "                                edges.append(edges_possibilities[j])\n",
    "                            else: \n",
    "                                import random\n",
    "                                edges.append(random.choice([edges_possibilities[i],edges_possibilities[j]]))\n",
    "    edges = list(set(edges))\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c9d6f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:38.951100Z",
     "start_time": "2022-09-13T04:00:38.945115Z"
    }
   },
   "outputs": [],
   "source": [
    "def bins_values(pais):\n",
    "    q = '''select \"Emission\" from pre_processed_data.bins_{pais} where \"Emission\" is not null'''.format(pais = pais)\n",
    "    conn = open_connection()\n",
    "    df = pd.read_sql(q,conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0149c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:39.271243Z",
     "start_time": "2022-09-13T04:00:39.264261Z"
    }
   },
   "outputs": [],
   "source": [
    "def real_values(pais, data):\n",
    "    q = '''select \"Emission\" from pre_processed_data.{pais} where \"Date\" = '{dataf}' '''.format(pais = pais, dataf = (data+timedelta(days = 1)).strftime(\"%Y/%m/%d\"))\n",
    "    conn = open_connection()\n",
    "    df = pd.read_sql(q,conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb5f78fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:00:59.573366Z",
     "start_time": "2022-09-13T04:00:59.514521Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(pais):\n",
    "    #initialize auxiliary variables\n",
    "    k=1 #total days used\n",
    "    target_variable = 'Emission'\n",
    "    edges_possibilities = []\n",
    "    edges_frequency = []\n",
    "    timemodel = []\n",
    "    timeinference = []\n",
    "    forecast_values = pd.DataFrame()\n",
    "\n",
    "    #read all available dates\n",
    "    dates = get_all_dates(pais)\n",
    "\n",
    "    #begin the forecast experiment\n",
    "    for i in tqdm(dates[7:8]):\n",
    "        #dataset to save de forecast values\n",
    "        forecast_aux = pd.DataFrame()\n",
    "        forecast_date = []\n",
    "        forecast_hour = []\n",
    "        forecast_v = []\n",
    "        #dataset to learn the model\n",
    "        data_learn = get_dataset(pais,i, i+timedelta(days = 0))\n",
    "        #structural learning with the dataset of day i\n",
    "        data_learn.drop(['Date','Hour'], axis = 1, inplace = True)\n",
    "        ti = time.time()\n",
    "        best_model = DM.EdgesModel(data_learn, FullOpt)[0]\n",
    "\n",
    "        #get the markov blanket\n",
    "        best_model = blanket(best_model, target_variable)\n",
    "\n",
    "        #update the edges frequencies\n",
    "        edges_possibilities, edges_frequency = update_edges_frequencies(best_model, edges_possibilities, edges_frequency)\n",
    "\n",
    "        #update threshold and select the edges\n",
    "        edges = update_threshold_select_edges(k, edges_possibilities, edges_frequency)\n",
    "\n",
    "        tf = time.time()\n",
    "        timemodel.append(tf-ti)\n",
    "        #forecast initial in day 8 (fit from 01 until 07)\n",
    "        if i >= dates[6] and i+timedelta(days = 1) in dates::\n",
    "            #bins\n",
    "            bins = bins_values(pais)\n",
    "            \n",
    "            #fit dataset (last 7 days)\n",
    "            fit_data = get_dataset(pais,i-timedelta(days = 6), i)\n",
    "            fit_dataall = get_dataset_allfeatures(pais,i-timedelta(days = 6), i)\n",
    "\n",
    "            #predict data of the entire day\n",
    "            predict_data_day = get_dataset(pais,i+timedelta(days = 1), i+timedelta(days = 1))\n",
    "            predict_dataall = get_dataset_allfeatures(pais,i+timedelta(days = 1), i+timedelta(days = 1))\n",
    "\n",
    "            #detects independent variables\n",
    "            independentes=[]\n",
    "            for col in fit_data.columns:\n",
    "                if col not in list(map(lambda x: x[0],edges))+list(map(lambda x: x[1],edges)):\n",
    "                    independentes.append(col)\n",
    "\n",
    "            #drop independent columns\n",
    "            fit_data.drop(independentes, axis=1, inplace = True)\n",
    "            predict_data_day.drop(independentes, axis=1, inplace = True)\n",
    "\n",
    "            #transform data in levels (limitation of PGMPY)\n",
    "            levels = {}\n",
    "            aux = fit_dataall.copy()\n",
    "            aux = aux.append(predict_dataall)\n",
    "            for var in aux.columns:\n",
    "                levels[var] = set(aux[var])\n",
    "                fit_dataall[var] = fit_dataall[var].replace(levels[var], np.arange(0,len(levels[var])))\n",
    "                predict_dataall[var] = predict_dataall[var].replace(levels[var], np.arange(0,len(levels[var])))\n",
    "                if var in fit_data.columns:\n",
    "                    fit_data[var] = fit_data[var].replace(levels[var], np.arange(0,len(levels[var])))\n",
    "                    predict_data_day[var] = predict_data_day[var].replace(levels[var], np.arange(0,len(levels[var])))\n",
    "            predict_data_day = predict_data_day.astype(int)\n",
    "            \n",
    "            #Using the edges, get the bayesian model object\n",
    "            model = BayesianModel(edges)\n",
    "\n",
    "            #aux\n",
    "            aux_fore = []\n",
    "        \n",
    "            #predict each point of day i+1\n",
    "            ti_inf = time.time()\n",
    "            for h in range(len(predict_data_day)):\n",
    "                forecast_date.append(i+timedelta(days = 1))\n",
    "                forecast_hour.append(h)\n",
    "                predict_data = predict_data_day.iloc[[h]]\n",
    "                predictall = predict_dataall.iloc[[h]]\n",
    "                fit_datah = fit_data.loc[0:len(fit_data)-3+h] #tau = 3 (forecast horizon)\n",
    "                \n",
    "                #fit the bayesian model to get de CPTs\n",
    "                model.fit(fit_datah)\n",
    "                model.get_cpds(node = target_variable)\n",
    "\n",
    "                #drop all variable in time window T+1 (unknown values - future states)\n",
    "                for c in predict_data.columns:\n",
    "                    if '-1' not in c:\n",
    "                        predict_data[c] = predictall[c+str('-1')]\n",
    "                del predict_data[target_variable]\n",
    "                \n",
    "                #solve limitation of unknown level \n",
    "                for col in predict_data.columns:\n",
    "                    predict_data[col][predict_data[col]>=len(set(fit_datah[col]))] = len(set(fit_datah[col]))-1\n",
    "                y_pred = model.predict(predict_data)\n",
    "                y_pred[target_variable] = y_pred[target_variable].replace(np.arange(0,len(levels[target_variable])),levels[target_variable])\n",
    "                for v in y_pred[target_variable]:\n",
    "                    aux_fore.append((bins[target_variable][v]+bins[target_variable][v+1])/2)\n",
    "                fit_data = fit_data.append(predict_data_day.loc[h-3:h-3]).reset_index(drop = True) \n",
    "            forecast_aux['Date'] = forecast_date\n",
    "            forecast_aux['Hour'] = forecast_hour\n",
    "            forecast_aux['Emissions Forecast'] = smooth(aux_fore,5)\n",
    "            real_value = real_values(pais, i)\n",
    "            forecast_aux[target_variable] = real_value[target_variable]\n",
    "            forecast_values = forecast_values.append(forecast_aux)\n",
    "            tf_inf = time.time()\n",
    "            timeinference.append(tf_inf-ti_inf)\n",
    "        k = k+1\n",
    "    #save the results on postgres\n",
    "    df_edges = pd.DataFrame()\n",
    "    df_edges['edges'] = edges_possibilities\n",
    "    df_edges['frequencia'] = edges_frequency\n",
    "    df_edges['total days'] = k-1\n",
    "    df_time_model = pd.DataFrame()\n",
    "    df_time_model['tempo'] = timemodel\n",
    "    df_time_inference = pd.DataFrame()\n",
    "    df_time_inference['tempo'] = timeinference\n",
    "    \n",
    "    df_edges.to_sql(name='edges_frequency_'+str(pais), con = get_connection(),schema = 'results', if_exists = 'replace', chunksize = None, index = False)\n",
    "    df_time_model.to_sql(name='time_model_'+str(pais), con = get_connection(),schema = 'results', if_exists = 'replace', chunksize = None, index = False)\n",
    "    df_time_inference.to_sql(name='time_inference_'+str(pais), con = get_connection(),schema = 'results', if_exists = 'replace', chunksize = None, index = False)\n",
    "    forecast_values.to_sql(name='forecast_'+str(pais), con = get_connection(),schema = 'results', if_exists = 'replace', chunksize = None, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fc4cc31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-13T04:03:35.098018Z",
     "start_time": "2022-09-13T04:01:16.762742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [02:16<00:00, 136.23s/it]\n"
     ]
    }
   ],
   "source": [
    "main('espanha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb35543c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T02:47:09.170586Z",
     "start_time": "2022-09-12T02:47:09.162610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE:  6.31499349207514\n",
      "MAE:  37.81498384126137\n",
      "MedAE:  34.9104457095642\n"
     ]
    }
   ],
   "source": [
    "print(\"NRMSE: \",np.sqrt((mean_squared_error(aux_fore['Emission'],aux_fore['Emissions Forecast']))/(max(aux_fore['Emission'])-min(aux_fore['Emission']))))\n",
    "print(\"MAE: \", mean_absolute_error(aux_fore['Emission'],aux_fore['Emissions Forecast']))\n",
    "print(\"MedAE: \", median_absolute_error(aux_fore['Emission'],aux_fore['Emissions Forecast']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "62498754",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T03:20:20.531580Z",
     "start_time": "2022-09-12T03:20:20.525596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE:  5.735187661252892\n",
      "MAE:  36.10798746002474\n",
      "MedAE:  32.001057093187285\n"
     ]
    }
   ],
   "source": [
    "print(\"NRMSE: \",np.sqrt((mean_squared_error(aux_fore['Emission'],smooth(aux_fore['Emissions Forecast'],5)))/(max(aux_fore['Emission'])-min(aux_fore['Emission']))))\n",
    "print(\"MAE: \", mean_absolute_error(aux_fore['Emission'],smooth(aux_fore['Emissions Forecast'],5)))\n",
    "print(\"MedAE: \", median_absolute_error(aux_fore['Emission'],smooth(aux_fore['Emissions Forecast'],5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c32fcef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T12:03:14.103098Z",
     "start_time": "2022-09-12T12:03:14.094121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE:  7.051595561925361\n",
      "MAE:  44.12230251179301\n",
      "MedAE:  46.690401681751496\n"
     ]
    }
   ],
   "source": [
    "print(\"NRMSE: \",np.sqrt((mean_squared_error(forecast_values['Emission'],forecast_values['Emissions Forecast']))/(max(forecast_values['Emission'])-min(forecast_values['Emission']))))\n",
    "print(\"MAE: \", mean_absolute_error(forecast_values['Emission'],forecast_values['Emissions Forecast']))\n",
    "print(\"MedAE: \", median_absolute_error(forecast_values['Emission'],forecast_values['Emissions Forecast']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "573d5779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-12T12:03:40.367281Z",
     "start_time": "2022-09-12T12:03:40.360299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NRMSE:  6.757625056591128\n",
      "MAE:  44.93697828374403\n",
      "MedAE:  37.69036249889736\n"
     ]
    }
   ],
   "source": [
    "print(\"NRMSE: \",np.sqrt((mean_squared_error(forecast_values['Emission'],smooth(forecast_values['Emissions Forecast'],5)))/(max(forecast_values['Emission'])-min(forecast_values['Emission']))))\n",
    "print(\"MAE: \", mean_absolute_error(forecast_values['Emission'],smooth(forecast_values['Emissions Forecast'],5)))\n",
    "print(\"MedAE: \", median_absolute_error(forecast_values['Emission'],smooth(forecast_values['Emissions Forecast'],5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83117cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b935613acb66c38ada86896ecd2c1ee112d390ac9871f93198d4ae2c0cafad7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
